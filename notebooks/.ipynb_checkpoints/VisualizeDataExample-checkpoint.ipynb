{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from os import listdir\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../data/ucf_sports_actions/ucf_action'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Diving-Side', 'Golf-Swing-Back', 'Golf-Swing-Front', 'Golf-Swing-Side', 'Kicking-Front', 'Kicking-Side', 'Lifting', 'Riding-Horse', 'Run-Side', 'SkateBoarding-Front', 'Swing-Bench', 'Swing-SideAngle', 'Walk-Front']\n"
     ]
    }
   ],
   "source": [
    "all_classes = []\n",
    "for class_name in listdir(dataset_path):\n",
    "    if '.' in class_name:\n",
    "        continue\n",
    "    all_classes.append(class_name)\n",
    "all_classes = sorted(all_classes)\n",
    "print(all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_classes = dict(enumerate(all_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes_to_index = {v: k for k, v in index_to_classes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_imagepath = {}\n",
    "for class_name in all_classes:\n",
    "    class_to_imagepath[class_name] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in all_classes:\n",
    "    class_path = dataset_path + '/' + class_name\n",
    "    for group in listdir(class_path):\n",
    "        if '.' in group:\n",
    "            continue\n",
    "        group_path = class_path + '/' + group\n",
    "        for image_i in listdir(group_path):\n",
    "            if '.jpg' not in image_i:\n",
    "                continue\n",
    "            image_path = group_path + '/' + image_i\n",
    "            class_to_imagepath[class_name].append(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_list_IDs = {}\n",
    "init_labels = {}\n",
    "count = 0\n",
    "for class_name in all_classes:\n",
    "    class_path = dataset_path + '/' + class_name\n",
    "    for group in listdir(class_path):\n",
    "        if '.' in group:\n",
    "            continue\n",
    "        group_path = class_path + '/' + group\n",
    "        for image_i in listdir(group_path):\n",
    "            if '.jpg' not in image_i:\n",
    "                continue\n",
    "            image_path = group_path + '/' + image_i\n",
    "            \n",
    "            init_list_IDs[count] = image_path\n",
    "            init_labels[count] = all_classes_to_index[class_name]\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UCF_Sports_Dataset(data.Dataset):\n",
    "#       '''Characterizes a dataset for PyTorch'''\n",
    "    def __init__(self, list_IDs, labels):\n",
    "        '''Initialization'''\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.transform = transforms.Compose(\n",
    "                [transforms.Resize((250, 250)),\n",
    "                    transforms.ToTensor(),\n",
    "#                     transforms.CenterCrop(10),\n",
    "                 \n",
    "                 transforms.Normalize((0.5, 0.5, 0.5), \n",
    "                                      (0.5, 0.5, 0.5))])\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Denotes the total number of samples'''\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Generates one sample of data'''\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image)\n",
    "        X = image\n",
    "        y = self.labels[index]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucf_dataset = UCF_Sports_Dataset(init_list_IDs, init_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = ucf_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(ucf_dataset,\n",
    "                                          batch_size=4,\n",
    "                                          shuffle=True,\n",
    "                                         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Classifier from Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicNet, self).__init__()\n",
    "        # torch.Size([64, 3, 250, 250])\n",
    "        # 3 input image channel (RGB), #6 output channels, 4x4 kernel \n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=(4,4), stride=1, \n",
    "                               padding=2, dilation=1, groups=1, \n",
    "                               bias=True, padding_mode='reflect')\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=(3,3))\n",
    "        self.conv3 = nn.Conv2d(16, 64, kernel_size=(3,3))\n",
    "        self.conv4 = nn.Conv2d(64, 8, kernel_size=(4,4))\n",
    "        self.fc1 = nn.Linear(128, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 13)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 5)\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "basicNet = BasicNet()\n",
    "# Try different optimzers here [Adam, SGD, RMSprop]\n",
    "optimizer = optim.RMSprop(basicNet.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 \tLoss: 717.890808\n",
      "Train Epoch: 0 \tLoss: 7076.216255\n",
      "Train Epoch: 0 \tLoss: 18128.013573\n",
      "Train Epoch: 0 \tLoss: 38464.048241\n",
      "Train Epoch: 0 \tLoss: 49668.939674\n",
      "Train Epoch: 0 \tLoss: 54896.599510\n",
      "Train Epoch: 0 \tLoss: 65750.032158\n",
      "Train Epoch: 0 \tLoss: 80321.003105\n",
      "Train Epoch: 1 \tLoss: 515.899475\n",
      "Train Epoch: 1 \tLoss: 13122.763870\n",
      "Train Epoch: 1 \tLoss: 19846.838112\n",
      "Train Epoch: 1 \tLoss: 30528.513542\n",
      "Train Epoch: 1 \tLoss: 52564.656990\n",
      "Train Epoch: 1 \tLoss: 69371.729591\n",
      "Train Epoch: 1 \tLoss: 82116.500389\n",
      "Train Epoch: 1 \tLoss: 91390.569794\n",
      "Train Epoch: 2 \tLoss: 241.600830\n",
      "Train Epoch: 2 \tLoss: 9112.735611\n",
      "Train Epoch: 2 \tLoss: 22313.243912\n",
      "Train Epoch: 2 \tLoss: 35987.357117\n",
      "Train Epoch: 2 \tLoss: 46190.536064\n",
      "Train Epoch: 2 \tLoss: 54275.876549\n",
      "Train Epoch: 2 \tLoss: 63858.799713\n",
      "Train Epoch: 2 \tLoss: 73886.575081\n"
     ]
    }
   ],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "max_epochs = 3\n",
    "\n",
    "training_losses = []\n",
    "\n",
    "# Generators\n",
    "training_set = ucf_dataset\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "    total_epoch_loss = 0\n",
    "    for batch_idx, (batch_data, batch_labels) in enumerate(training_generator):\n",
    "        \n",
    "        output = basicNet(batch_data)\n",
    "        target = batch_labels\n",
    "        \n",
    "        loss = F.nll_loss(output, target)   # Compute loss\n",
    "        loss.backward()                     # Gradient computation\n",
    "        optimizer.step()  \n",
    "        total_epoch_loss += loss.item()\n",
    "    \n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} \\tLoss: {:.6f}'.format(\n",
    "                epoch, total_epoch_loss))\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        with open('../saved_models/basic_network2.pkl', 'wb') as f:\n",
    "            torch.save(basicNet.state_dict(), f)\n",
    "    training_losses.append(total_epoch_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "correct = 0\n",
    "total = 0\n",
    "for batch_idx, (batch_data, batch_labels) in enumerate(training_generator):\n",
    "\n",
    "    output = basicNet(batch_data)\n",
    "    pred = torch.argmax(output, axis=1)\n",
    "#     print(output.shape)\n",
    "#     print(target.shape)\n",
    "    target = batch_labels\n",
    "    \n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "#     for i in range(len(target)):\n",
    "#         if target[i]==predicted[i]:\n",
    "#             correct += 1\n",
    "#         total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9520"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ucf_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.04411764705882353\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy = \", correct/ucf_dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = ucf_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = AlexNet()\n",
    "loaded_model.load_state_dict(torch.load('../saved_models/saved_models/alex_network3.pkl')\n",
    "                            \n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "index =  0\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  1\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  2\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  3\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  4\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  5\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  6\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  7\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  8\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  9\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  10\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  11\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  12\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  13\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  14\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  15\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  16\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  17\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  18\n",
      "true_class: 0, predicted_class: 2\n",
      "\n",
      "index =  19\n",
      "true_class: 0, predicted_class: 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(\"\\nindex = \", i)\n",
    "    x,y = ucf_dataset.__getitem__(i)\n",
    "    image = x.unsqueeze(0)\n",
    "\n",
    "    output_probs = basicNet(image)\n",
    "    predicted_class = torch.argmax(output_probs)\n",
    "    true_class = y\n",
    "\n",
    "    print('true_class: {}, predicted_class: {}'.format(true_class, predicted_class) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (batch_data, batch_labels) in enumerate(training_generator):\n",
    "    output = basicNet(batch_data)\n",
    "    pred = basic_\n",
    "    \n",
    "    break\n",
    "# target = batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../saved_models/basic_network1.pkl', 'wb') as f:\n",
    "    torch.save(basicNet.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
