{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from os import listdir\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../data/ucf_sports_actions/ucf_action'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Diving-Side', 'Golf-Swing-Back', 'Golf-Swing-Front', 'Golf-Swing-Side', 'Kicking-Front', 'Kicking-Side', 'Lifting', 'Riding-Horse', 'Run-Side', 'SkateBoarding-Front', 'Swing-Bench', 'Swing-SideAngle', 'Walk-Front']\n"
     ]
    }
   ],
   "source": [
    "all_classes = []\n",
    "for class_name in listdir(dataset_path):\n",
    "    if '.' in class_name:\n",
    "        continue\n",
    "    all_classes.append(class_name)\n",
    "all_classes = sorted(all_classes)\n",
    "print(all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_classes = dict(enumerate(all_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes_to_index = {v: k for k, v in index_to_classes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_imagepath = {}\n",
    "for class_name in all_classes:\n",
    "    class_to_imagepath[class_name] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in all_classes:\n",
    "    class_path = dataset_path + '/' + class_name\n",
    "    for group in listdir(class_path):\n",
    "        if '.' in group:\n",
    "            continue\n",
    "        group_path = class_path + '/' + group\n",
    "        for image_i in listdir(group_path):\n",
    "            if '.jpg' not in image_i:\n",
    "                continue\n",
    "            image_path = group_path + '/' + image_i\n",
    "            class_to_imagepath[class_name].append(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_list_IDs = {}\n",
    "init_labels = {}\n",
    "count = 0\n",
    "for class_name in all_classes:\n",
    "    class_path = dataset_path + '/' + class_name\n",
    "    for group in listdir(class_path):\n",
    "        if '.' in group:\n",
    "            continue\n",
    "        group_path = class_path + '/' + group\n",
    "        for image_i in listdir(group_path):\n",
    "            if '.jpg' not in image_i:\n",
    "                continue\n",
    "            image_path = group_path + '/' + image_i\n",
    "            \n",
    "            init_list_IDs[count] = image_path\n",
    "            init_labels[count] = all_classes_to_index[class_name]\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UCF_Sports_Dataset(data.Dataset):\n",
    "#       '''Characterizes a dataset for PyTorch'''\n",
    "    def __init__(self, list_IDs, labels):\n",
    "        '''Initialization'''\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.transform = transforms.Compose(\n",
    "                [transforms.Resize((250, 250)),\n",
    "                    transforms.ToTensor(),\n",
    "#                     transforms.CenterCrop(10),\n",
    "                 \n",
    "                 transforms.Normalize((0.5, 0.5, 0.5), \n",
    "                                      (0.5, 0.5, 0.5))])\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Denotes the total number of samples'''\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Generates one sample of data'''\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image)\n",
    "        X = image\n",
    "        y = self.labels[index]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucf_dataset = UCF_Sports_Dataset(init_list_IDs, init_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = ucf_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(ucf_dataset,\n",
    "                                          batch_size=4,\n",
    "                                          shuffle=True,\n",
    "                                         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Classifier from Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicNet, self).__init__()\n",
    "        # torch.Size([64, 3, 250, 250])\n",
    "        # 3 input image channel (RGB), #6 output channels, 4x4 kernel \n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=(4,4), stride=1, \n",
    "                               padding=2, dilation=1, groups=1, \n",
    "                               bias=True, padding_mode='reflect')\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=(3,3))\n",
    "        self.conv3 = nn.Conv2d(16, 64, kernel_size=(3,3))\n",
    "        self.conv4 = nn.Conv2d(64, 8, kernel_size=(4,4))\n",
    "        self.fc1 = nn.Linear(128, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 13)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 5)\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "basicNet = BasicNet()\n",
    "# Try different optimzers here [Adam, SGD, RMSprop]\n",
    "optimizer = optim.RMSprop(basicNet.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 \tLoss: 717.890808\n",
      "Train Epoch: 0 \tLoss: 7076.216255\n",
      "Train Epoch: 0 \tLoss: 18128.013573\n",
      "Train Epoch: 0 \tLoss: 38464.048241\n",
      "Train Epoch: 0 \tLoss: 49668.939674\n",
      "Train Epoch: 0 \tLoss: 54896.599510\n",
      "Train Epoch: 0 \tLoss: 65750.032158\n",
      "Train Epoch: 0 \tLoss: 80321.003105\n",
      "Train Epoch: 1 \tLoss: 515.899475\n",
      "Train Epoch: 1 \tLoss: 13122.763870\n",
      "Train Epoch: 1 \tLoss: 19846.838112\n",
      "Train Epoch: 1 \tLoss: 30528.513542\n",
      "Train Epoch: 1 \tLoss: 52564.656990\n"
     ]
    }
   ],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "max_epochs = 3\n",
    "\n",
    "training_losses = []\n",
    "\n",
    "# Generators\n",
    "training_set = ucf_dataset\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "    total_epoch_loss = 0\n",
    "    for batch_idx, (batch_data, batch_labels) in enumerate(training_generator):\n",
    "        \n",
    "        output = basicNet(batch_data)\n",
    "        target = batch_labels\n",
    "        \n",
    "        loss = F.nll_loss(output, target)   # Compute loss\n",
    "        loss.backward()                     # Gradient computation\n",
    "        optimizer.step()  \n",
    "        total_epoch_loss += loss.item()\n",
    "    \n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} \\tLoss: {:.6f}'.format(\n",
    "                epoch, total_epoch_loss))\n",
    "    \n",
    "    training_losses.append(total_epoch_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
